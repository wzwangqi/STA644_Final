---
title: "Global Terrorist Activities Time Series Analysis and Iraq Spatial Case Study"
author: "Yuan Gao, Qi Wang, Yizheng Wang, Darien Zhang"
date: "4/21/2017"
output: pdf_document
---

## Introduction

This project aims to explore and analyze the dataset from Global Terrorism Database that contains details on every terrorist activity since 1970. There are two parts of the project. The first part is creating time series models for aggregated count data for terrorist activities in each region of the world. We aggregated the incidents to yearly and monthly basis count data and built ARIMA models with seasonal trends to forecast the number of attacks in the future years. The second part focuses on the spatial pattern of these terroristic attacks in Iraq, which is a country that suffered the most from terrorism: over 18,000 attacks took place in Iraq from 1970 to 2015. In addition, we incorporated the civilian deaths dataset from the Iraq Body Count website, which could be used to conduct inference on the number of attacks and the total civilian deaths from violence. In order to capture the spatial patterns, several spatial models including SAR, CAR and their corresponding bayesian version models have been implemented. In the GTD dataset, there is a categorical variable which is called `success`. Success of a terrorist strike is defined with respect to the tangible effects of the attack. Based on this variable, we also fit a spline model which can be used to predict which areas of Iraq have high success rate in terrorist attacks.

## Data
The Global Terrorism Database (GTD) is maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START). The database collects from media articles and electronic archives, and to a lesser extent, existing data sets, secondary source materials such as books and journals, and legal documents. Each row represents one terrorist incident, and the variables include incident date, incident information, incident location, attack information, weapon information, target information, and perpetrator information. There are 156,772 incidents ranging from 1970 to 2015. The GTD defines a terrorist attack as the threatened or actual use of illegal force and violence by a non\-state actor to attain a political, economic, religious, or social goal through fear, coercion, or intimidation. In order to consider an incident for inclusion in the GTD, all three of the following attributes must be present: the incident must be intentional, the incident must entail some level of violence or immediate threat of violence, and the perpetrators of the incidents must be sub\-national actors. Incidents occurring in both the same geographic and temporal point will be regarded as a single incident, but if either the time of occurrence of incidents or their locations are discontinuous, the events will be regarded as separate incidents.


We also incorporated another source of data for the spatial analysis from Iraq Body Count. Iraq Body Count (IBC) maintains the world's largest public database of violent civilian deaths. Its data drawn from cross-checked media reports, hospital, morgue, NGO and official figures or records. IBC can allow user to specify the number of civilian deaths for each province. Hence, we are able to cumulatively sum the number of civilian deaths for each province of Iraq and use these data to fit models.

## Methodology

### Time Series Analysis

The AR(1) process is  
$$AR(1): \quad y_t = \delta + \phi \, y_{t-1} + w_t $$

A moving average process is similar to an AR process, except that the autoregression is on the error term.
$$ MA(1): \qquad y_t = \delta + w_t + \theta \, w_{t-1} $$


An ARMA model is a composite of AR and MA processes,

$$
\begin{aligned}
ARMA(p,q): \quad\quad\\
   y_t &= \delta + \phi_1 \, y_{t-1} + \cdots \phi_p \, y_{t-p} + w_{t} + \theta_1 w_{t-1} + \cdots + \theta_q w_{t_q} \\
  \phi_p(L) y_t &= \delta + \theta_q(L)w_t 
\end{aligned}
$$

We used Autoregressive integrated moving average (ARIMA) to build our models, which is an extension of an $ARMA$ model to include differencing of degree $d$ to $y_t$ before including the autoregressive and moving average components. Differencing is
$ \Delta y_t = y_t - y_{t-1} $, and $\Delta^d \, y_t$ is repeated applications of this operator.


$$
\begin{aligned}
ARIMA(p,d,q): \qquad \phi_p(L) \; \Delta^d \, y_t &= \delta + \theta_q(L) w_t  
\end{aligned}
$$

### Spatial Analysis

Originated from time series analysis, *Simultaneous Autoregressive (SAR)* model and *Conditional Autoregressive (CAR)* model have been applied and extended by different fields such as econometrics, geography and medical statistics. Analogy to *Autoregressive model*, the CAR and SAR models include spatial neighboring observations. Here we fit the SAR and CAR model by both Frequentist and Bayesian way to discover spatial patterns of terroristic attacks in Iraq.

Similar to kernel regression and k-nearest-neighbors regression, *Smoothing Spline* model is able to flexibly estimate underlying regression function $f(x)$. We used *Smoothing Spline* model to discover how ``successful terroristic attack'' distributes in Iraq.

#### SAR and CAR

For every spatial data point $s$, *Simultaneous Autoregressive* assumes:

$$ y(s) = \phi \sum_{s'} \frac{W_{s\,s'}}{W_{s\,\boldsymbol{\cdot}}} y(s') + \epsilon $$

$$ {y} \sim \mathcal{N}(0,~\sigma^2 \, (({I}-\phi {W})^{-1}) (({I}-\phi {W})^{-1})^t )$$

*Conditional Autoregressive* assumes:

$$ y(s)|{y}_{-s} \sim \mathcal{N}\left(\sum_{s'} \frac{W_{s\,s'}}{W_{s\,\boldsymbol{\cdot}}} y(s'),~ \sigma^2 \right) $$

$$ {y} \sim \mathcal{N}(0,~\sigma^2 \, ({I}-\phi {W})^{-1})$$

Where $W$ is weight matrices and $\sigma^2$ is variance. 

#### Spline 

Spline provides a flexible way of estimating the underlying regression function $r(x)=E(Y|X=x)$. It estimates values using a mathematical function that minimizes overall surface curvature. This results in a smooth surface that passes exactly through the input points. In the spatial context, it can predict ridges and valleys in the data and is the best method for representing the smoothly varying surfaces(Childs, 2014). The general spline formula is as follows: $$S(x,y)=T(x,y)+\sum_{j=1}^{N}\lambda_jR(r_j),$$ where N is the number of points, $\lambda$ is the coefficients, and $r_j$ is the distance from the point (x,y) to the $j^{th}$ point. $T(x,y)$ and $R(r)$ represent tension option and regularized option, respectively. They are defined differently and really depend on the specific context.

## Result

### Part I: Regional Time Series Analysis

The first part of the project is to build ARIMA models for all twelve regions on aggregated counts of the incidents and perform forecasts for the next several years. We performed the analysis on both yearly and monthly aggregated count data.

Looking at the plots of the original data in Appendix, we can see that there are obvious drifts in the original time series. For fulfilling stationarity, we have visualize the difference of the original data. After differencing, data does seem to appear to have a mean at 0. Corresponding ACF and PACF are also plotted for modeling. Periodograms are plotted, and they can be used to identify the dominant periods (or frequencies) of a time series.  Periodogram is a helpful tool in spectral analysis to detect cyclical behavior. Typically the time series are observed in time domain, but it can also be transformed to the frequency domain by Fourier Transformation. If there is significant peak at certain frequency, there may be significant periodicity in the series.

Based on observing the ACF, PACF and periodogram, by grid searching on a small range, here we have presented the best models. For the models based on yearly data, they turn out to have relatively low AIC values and the residuals are not autocorrelated. Thus, the models are good enough for us to use for forecast. For the monthly data, the residuals are not behaving as nicely looking at the acf and pacfs, and further tuning or more complicated models could be used to enhance the performance in the future. All of these plots can be found in the Appendix.

The plot below shows the yearly forecasted trends for the regions, and they seem to match up with our expectations of the number of terrorist attacks in the region. For instance, due to influx of refugees to Western Europe and complexity in the international politics of the region, an increase in the number of terrorist incidents could be expected in Western Europe as indicated by the model. Since we do not have ground truth on the actual terrorist attack counts in the future, we cannot validate our prediction. We also need to keep in mind that terrorist attacks have complicated motives and are triggered by many elements and the models are just a quick look at the trends to provide some insights in the matter. 

```{r, fig.height=6.5,fig.width=6, echo = F}
# (S)ARIMA modeling for 12 regions

par(mfrow = c(4,3),mar=c(4,2,1.5,1))

# North America
testarma=Arima(data1_count$count,order=c(1,1,1),seasonal=list(order=c(0,0,1),period=6))
testarma_res1 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[1,'region_txt'])


testarma=Arima(data2_count$count,order=c(0,1,1),seasonal=list(order=c(1,0,1),period=2))
testarma_res2 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[2,'region_txt'])

testarma=Arima(data3_count$count,order=c(5,1,1),seasonal=list(order=c(2,0,1),period=4))
testarma_res3 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[3,'region_txt'])

testarma=Arima(data4_count$count,order=c(3,1,3))
testarma_res4 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[4,'region_txt'])

testarma=Arima(data5_count$count,order=c(1,1,1),seasonal=list(order=c(2,0,1),period=4))
testarma_res5 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[5,'region_txt'])

testarma=Arima(data6_count$count,order=c(0,1,2),seasonal=list(order=c(2,0,1),period=6))
testarma_res6 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[6,'region_txt'])

testarma=Arima(data7_count$count,order=c(1,1,1),seasonal=list(order=c(2,0,1),period=2))
testarma_res7 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[7,'region_txt'])

testarma=Arima(data8_count$count,order=c(5,2,3))
testarma_res8 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[8,'region_txt'])

testarma=Arima(data9_count$count,order=c(3,1,2),seasonal=list(order=c(0,0,1),period=2))
testarma_res9 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[9,'region_txt'])

testarma=Arima(data10_count$count,order=c(5,1,5),seasonal=list(order=c(3,0,1),period=4))
testarma_res10 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[10,'region_txt'])

testarma=Arima(data11_count$count,order=c(5,1,3),seasonal=list(order=c(2,0,1),period=2))
testarma_res11 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[11,'region_txt'])

testarma=Arima(data12_count$count,order=c(2,1,3))
testarma_res12 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[12,'region_txt'])


```

\begin{center}
Yearly Forecast
\end{center}

### Part II: Iraq Spatial Analysis

#### Spatial Autocorrelation
Before we apply any statistical model to detect spatial patterns of terroristic attacks in Iraq, we use *Moran's I* and *Geary's C* to measure spatial autocorrelation of terroristic attack observation in Iraq.

Values of Moran's I range from $-1$ to $+1$. Negative values indicate negative spatial autocorrelation and positive values indicate positive spatial autocorrelation. A zero value indicates a random spatial pattern. 

The value of Geary's C lies between 0 and 2. 1 means no spatial autocorrelation. Values lower than 1 demonstrate increasing positive spatial autocorrelation, whilst values higher than 1 illustrate increasing negative spatial autocorrelation.

| Measurement   | Value         |
| ------------- |:-------------:|
| Moran's I     | 0.27          | 
| Geary's C     | 0.77          |
Table: Measurement of Spatial Autocorrelation

In our Iraq terroristic attack dataset, we calculate its Moran's I and Geary's C. Table.1 shows there is spatial pattern among the observations. Therefore, we decide to fit the *CAR*, *SAR* and *Spline* models to explore terroristic attacks in Iraq. 
```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Load packages
library(dplyr)
library(forecast)
library(ggplot2)
library(modelr)
library(tidyr)
library(readr)
library(spdep)
library(magrittr)
library(dplyr)
library(modelr)
library(ggplot2)
library(tidyr)
library(rjags)
library(stringr)
library(gridExtra)
library(readr)
library(purrr)
library(forcats)
library(forecast)
library(astsa)
library(fields)
library(readr)
library(sf)
globalterrorismdb_0616dist = readr::read_csv("globalterrorismdb_0616dist.csv")
load("iraq1.RData")
W = 1*st_touches(irq1$geometry, sparse=FALSE)
listW = mat2listw(W)

```


####Sar model with population density as predictor
In the GTD dataset, most of the columns are categorical variables, which can not be used as predictors in this context. Based on common knowledge, we speculate that most of the terroristic attacks took place in high population density area in order to reach their goal: attracting more attention from others. Therefore, we first use population density of each province in Iraq as the predictor to predict the number of attacks.
```{r, message=FALSE, warning=FALSE, echo=FALSE}
irq_sar_pop = spautolm(formula = count ~ density11, data = irq1, 
                  listw = listW, family = "SAR")
irq1$sar_pred_pop = irq_sar_pop$fit$fitted.values

irq1$sar_resid_pop = irq_sar_pop$fit$residuals
grid.arrange(
ggplot() + geom_sf(data=irq1, aes(fill=count)) + ggtitle("Number of Attacks"),
ggplot() + geom_sf(data=irq1, aes(fill=sar_pred_pop)) + ggtitle("Prediction from Population Density"),ncol=2)
```



#### Prediction Based on Civilian Death



```{r,message=FALSE, warning=FALSE, echo=FALSE}

irq_car = spautolm(formula = count ~ headcount, data = irq1, 
                  listw = listW, family = "CAR") 
irq_sar = spautolm(formula = count ~ headcount, data = irq1, 
                  listw = listW, family = "SAR")
irq1$car_pred = irq_car$fit$fitted.values
irq1$sar_pred = irq_sar$fit$fitted.values

irq1$car_resid = irq_car$fit$residuals
irq1$sar_resid = irq_sar$fit$residuals
grid.arrange(
ggplot() + geom_sf(data=irq1, aes(fill=count)) + ggtitle("Number of Attacks"),

ggplot() + geom_sf(data=irq1, aes(fill=headcount)) + ggtitle("# Civilian Deaths from Violence"),ncol=2
)
```


Given there is spatial pattern among terroristic attacks in Iraq, we use the number of civilian deaths from violence to predict the number of attacks in Iraq. In this case, we apply CAR and SAR using both Frequentist and Bayesian approaches to predict.

```{r,message=FALSE, warning=FALSE, echo=FALSE}
grid.arrange(
  ggplot() + geom_sf(data=irq1, aes(fill=car_pred)),
  ggplot() + geom_sf(data=irq1, aes(fill=sar_pred)),
  ggplot() + geom_sf(data=irq1, aes(fill=car_resid)),
  ggplot() + geom_sf(data=irq1, aes(fill=car_resid))
)
```

```{r,message=FALSE, warning=FALSE, echo=FALSE}

theme_set(
  theme_bw()  
)

get_coda_parameter = function(coda, pattern)
{
  w = coda[[1]] %>% colnames() %>% str_detect(pattern)
  coda[[1]][,w,drop=FALSE]
}

post_summary = function(m, ci_width=0.95)
{
  d = data_frame(
    post_mean  = apply(m, 2, mean),
    post_med   = apply(m, 2, median),
    post_lower = apply(m, 2, quantile, probs=(1-ci_width)/2),
    post_upper = apply(m, 2, quantile, probs=1 - (1-ci_width)/2)
  )
  
  if (!is.null(colnames(m)))
    d = d %>% mutate(param = colnames(m)) %>% dplyr::select(param, post_mean:post_upper)
  
  d
}

strip_attrs = function(obj)
{
  attributes(obj) = NULL
  obj
}

strip_class = function(obj)
{
  attr(obj,"class") = NULL
  obj
}
```



```{r,message=FALSE, warning=FALSE, echo=FALSE}
# JAGS CAR Model

y = irq1$count
x = irq1$headcount

W = W * 1L
D = diag(rowSums(W))

car_model = "model{
  y ~ dmnorm(beta0 + beta1*x, tau * (D - phi*W))
  y_pred ~ dmnorm(beta0 + beta1*x, tau * (D - phi*W))
  
  beta0 ~ dnorm(0, 1/100)
  beta1 ~ dnorm(0, 1/100)

  tau <- 1 / sigma2
  sigma2 ~ dnorm(0, 1/100) T(0,)
  phi ~ dunif(-0.99, 0.99)
}"
#cat(car_model,"\n")

if (!file.exists("irq_car_model.Rdata"))
{
  m = jags.model(
    textConnection(car_model), 
    data = list(
      D = D,
      y = y,
      x = x,
      W = W
    ),
    n.adapt=5000
  )

  update(m, n.iter=30000)#, progress.bar="none")
  
  irq_car_coda = coda.samples(
    m, variable.names=c("sigma2", "beta0", "beta1", "phi","y_pred"),
    n.iter=30000, thin=20
  )
  save(irq_car_coda, car_model, m, file="irq_car_model.Rdata")
} else {
  load("irq_car_model.Rdata")
}

beta_params = get_coda_parameter(irq_car_coda,"beta")
ar_params = get_coda_parameter(irq_car_coda,"sigma|phi")
y_pred = get_coda_parameter(irq_car_coda,"y_pred") %>% post_summary()
irq1$jags_pred = y_pred$post_mean
irq1$jags_resid = irq1$count - y_pred$post_mean
```


As the graphs show, the predicted maps are similar to the observed attack map. However, the predicted maps from the CAR and SAR models by Frequentist approach are more accurate than the models by Bayesian approach. Table.2 shows Car model using the Frequentist approach performs best among all models in terms of RMSE. If considering Moran's I of Residual and Geary's C of Residual, SAR model by the Frequentist approach performs best overall, since there is almost no hidden spatial pattern in its residual.


```{r,message=FALSE, warning=FALSE, echo=FALSE}
grid.arrange(
  ggplot() + geom_sf(data=irq1, aes(fill=car_pred)),
  ggplot() + geom_sf(data=irq1, aes(fill=jags_pred)),
  ggplot() + geom_sf(data=irq1, aes(fill=car_resid)),
  ggplot() + geom_sf(data=irq1, aes(fill=jags_resid))
)

```

However, we can still observe some hidden spatial pattern from Moran's I of Residual and Geary's C of Residual in the JAGS models. Moreover, the RMSE of the JAGS models is also more than 40% higher than that of Frequentist models. We think it might be caused by limited iteration. The performance of the JAGS model might be better, if we add more iterations.


| Model         | RMSE          | Moran's I of Residual| Geary's C of Residual|
| ------------- |:-------------:|:--------------------:|:--------------------:|
| SAR           | 295.02        | 0.01                 |1.11                  |
| CAR           | 273.29        | 0.30                 |0.76                  |
| SAR JAGS      | 422.51        | -0.32                |1.46                  |
| CAR JAGS      | 413.75        | 0.05                 |1.14                  |
Table: RMSE, Moran's I of Residual and Geary's C of Residual

####Spline model results

As mentioned before, spline model is like bending a sheet of rubber so that it passed through the points while minimizing the total curvature of the surface. Compared to the SAR and CAR models, the spline model can capture the spatial pattern more precisely. Especially for predicting ridges and valleys, the spline will perform much better than SAR and CAR model. In this project, spatial patterns for these terroristic attacks are highly similar to the rugged terrain since these attacks always take place in the area where it has high density of either population or energy. 


```{r,message=FALSE, warning=FALSE, echo=FALSE}
library(raster)
library(maptools)
data(wrld_simpl)
country=globalterrorismdb_0616dist[which(globalterrorismdb_0616dist$country==95),]
nal=-which(is.na(country$longitude))
country1=country[nal,]
r = raster(nrows=200, ncol=400,
           xmn = min(country1$longitude)*1.05, xmx = max(country1$longitude)*0.95,
           ymn = min(country1$latitude )*0.95, ymx = max(country1$latitude )*1.05)
country_iraq = rasterize(wrld_simpl[wrld_simpl$NAME == "Iraq",], r)
cells = which(!is.na(country_iraq []))
pred_coords = xyFromCell(r, cells)
library(fields)
#coords = select(csn, longitude, latitude) %>% as.matrix()
coords=country1[,c("longitude","latitude")] %>% as.matrix()

tps = Tps(x = coords, Y=country1$success)

iraqattack_pred = r
iraqattack_pred[cells] = predict(tps, pred_coords)


plot(iraqattack_pred,xlim=c(30,50),ylim=c(25,38))
points(coords, pch=16, cex=0.5)
title(main="spline model prediction",xlab="Longitude", ylab = "Latitude")


```


Instead of trying to explain the spatial patterns of terroristic attacks using splines, we use spline to predict the spatial pattern of success rate of attacks across the Iraq. As can be seen in the above plots, most of the attacks concentrating in the center of Iraq have high success rates. Not surprisingly, the capital city, Baghdad, is also located in the center of Iraq. Only a small amount of attacks took place in the south of Iraq but with high success rate. However, although a lot of attacks took place on the northern provinces compared to the southern region, the success rate is relatively low.

## Conclusion

For this project, we utilized methods learnt from this class using both time series and spatial models and applied them on the terrorist attack dataset from Global Terrorism Database. We used ARIMA models to forecast attack counts for different regions of the world and were able to obtain models that match the current global political situations. 

This project sheds some light on the complicated situation of terrorist attacks with models that are easy to intepret. To improve the results of our models, we can take further steps such as incorporating outside sources of data in the analysis and further tuning of the models. 

\newpage
## Appendix

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Load packages
library(dplyr)
library(forecast)
library(ggplot2)
library(modelr)
library(tidyr)
```

```{r,echo = F,fig.height=8,fig.width=7}
#Load data
data = read.csv('globalterrorismdb_0616dist.csv', header = T)
regions = data[,c('region','region_txt')]
reg_uniq = unique(regions) 
reg_uniq = reg_uniq[order(reg_uniq$region),]
n = nrow(reg_uniq)

# Create yearly and monthly data
for (i in 1:n){
  var = paste0("data",i,"_count")
  var1 = paste0("data",i,"_month")
  assign(var, data %>% filter(region == i) %>% group_by(iyear) %>% summarise(count = n()))
  assign(var1, data %>% filter(region == i) %>% group_by(iyear, imonth) %>% summarise(count = n()))
}

for (i in 1:n){
  use = get(paste0("data",i,"_month"))
  use = use[which(use$imonth != 0),]
  assign(paste0("data",i,"_month"),use)
}

for(i in 1:n){
  d = get(paste0("data",i,"_month"))
  assign(paste0("ts",i),ts(d$count, frequency = 12, start = c(1970,1)))
}

```

```{r,echo = F,fig.height=6.5,fig.width=6, fig.align = 'center'}
par(mfrow = c(4,3),mar=c(2,2,2,1))

for(i in 1:n){
  plot(get(paste0("data",i,"_count")), type = 'l', main = reg_uniq[i,'region_txt'])
}


```

\begin{center}
Yearly Count
\end{center}



```{r,eval = F, fig.height=8,fig.width=7, echo = F}
par(mfrow = c(3,4))
for (i in 1:12){
  var = paste0("fit",i)
  dat = get(paste0("data",i,"_count"))
  da = ts(dat$count, start = 1970)
  assign(var, auto.arima(da, stepwise = FALSE, seasonal = TRUE))
  this = get(paste0("fit",i))
  plot(forecast(this,h=5), main = reg_uniq[i,'region_txt'])
  var1 = paste0("residual",i)
  assign(var1, this$residuals)
}

par(mfrow=c(1,3), mar=c(2,4,6,2))
for (i in 1:n){
  res = get(paste0("residual",i))
  plot(res,main=reg_uniq[i,'region_txt'])
  acf(res)
  pacf(res)
}


par(mfrow = c(3,4))
for (i in 1:12){
  var = paste0("fit_month",i)
  dat = get(paste0("ts",i))
  assign(var, auto.arima(dat, stepwise = FALSE, seasonal = TRUE))
  this = get(paste0("fit_month",i))
  plot(forecast(this,h=50), main = reg_uniq[i,'region_txt'])
  var1 = paste0("residual_month",i)
  assign(var1, this$residuals)
}

par(mfrow=c(1,3), mar=c(2,4,6,2))
for (i in 1:n){
  res = get(paste0("residual_month",i))
  plot(res,main=reg_uniq[i,'region_txt'])
  acf(res)
  pacf(res)
}
```

```{r,echo = F}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r, eval = F, echo = F}

for(i in 1:12){
  data_in_use = get(paste0("data",i,"_count"))
  l = lm(count~iyear, data = data_in_use)
  l2 = lm(count ~ iyear + I(iyear^2), data=data_in_use)
  
  d = data_in_use %>%
    add_predictions(l, var="l") %>%
    add_predictions(l2, var="l2")
  
  var = paste0("p",i)
  assign(var,ggplot(data_in_use, aes(x=iyear, y=count)) + 
           geom_line() + 
           geom_point() +
           geom_line(data=d, aes(x=iyear, y=l), color="red", size=1.2) +
           geom_line(data=d, aes(x=iyear, y=l2), color="blue", size=1.2)+
           ggtitle(reg_uniq[i,'region_txt']))
  
  d = data_in_use %>%
    add_residuals(l, var="resid_l") %>%
    add_residuals(l2, var="resid_q")
  
  var = paste0("r",i)
  
  assign(var,ggplot(gather(d, type, residual, -(iyear:count)), aes(x=iyear, y=residual, color=type)) + 
           geom_point() +
           geom_line() +
           facet_wrap(~type, nrow=2)+
           ggtitle(reg_uniq[i,'region_txt']))
}
multiplot(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12, cols = 4)
multiplot(r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12, cols = 4)


```







```{r, echo = F, fig.height=6.5,fig.width=6.5}
# ACF and PACF for yearly data

par(mfrow = c(4,3),mar=c(1,2,3,1))

for(i in 1:n){
  var = paste0("diff",i)
  data_c = get(paste0("data",i,"_count"))
  assign(var, diff(data_c$count))
  data_diff = get(paste0("diff",i))
  plot(data_diff, type = 'l', main = reg_uniq[i,'region_txt'])

}
```

\begin{center}
Differenced Data
\end{center}

```{r, echo = F, fig.height=6.5,fig.width=6.5}
par(mfrow = c(4,3),mar=c(1,2,3,1))

for(i in 1:n){
  data_diff = get(paste0("diff",i))
  acf(data_diff,main = reg_uniq[i,'region_txt'])
}

```

\begin{center}
acf
\end{center}

```{r, echo = F, fig.height=6.5,fig.width=6.5}
par(mfrow = c(4,3),mar=c(1,2,3,1))

for(i in 1:n){
  data_diff = get(paste0("diff",i))
  pacf(data_diff,main = reg_uniq[i,'region_txt'])
}
```

\begin{center}
pacf
\end{center}

```{r,fig.height=6.5,fig.width=6, echo = F, eval = F}
# Periodogram for yearly data
par(mfrow = c(4,3),mar=c(4,2,1.5,1))
for(i in 1:n){
  data_diff = get(paste0("diff",i))
  var = paste0("perio",i)
  assign(var,spec.pgram(data_diff,taper=0,log="no",main=reg_uniq[i,'region_txt']))
}

spec.pgram(diff11,taper=0,log="no",main=reg_uniq[11,'region_txt'])
```

\begin{center}
Periodogram
\end{center}


```{r, fig.height=6.5,fig.width=6, echo = F}
# (S)ARIMA modeling for 12 regions

par(mfrow = c(4,3),mar=c(4,2,1.5,1))

# North America
testarma=Arima(data1_count$count,order=c(1,1,1),seasonal=list(order=c(0,0,1),period=6))
testarma_res1 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[1,'region_txt'])


testarma=Arima(data2_count$count,order=c(0,1,1),seasonal=list(order=c(1,0,1),period=2))
testarma_res2 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[2,'region_txt'])

testarma=Arima(data3_count$count,order=c(5,1,1),seasonal=list(order=c(2,0,1),period=4))
testarma_res3 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[3,'region_txt'])

testarma=Arima(data4_count$count,order=c(3,1,3))
testarma_res4 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[4,'region_txt'])

testarma=Arima(data5_count$count,order=c(1,1,1),seasonal=list(order=c(2,0,1),period=4))
testarma_res5 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[5,'region_txt'])

testarma=Arima(data6_count$count,order=c(0,1,2),seasonal=list(order=c(2,0,1),period=6))
testarma_res6 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[6,'region_txt'])

testarma=Arima(data7_count$count,order=c(1,1,1),seasonal=list(order=c(2,0,1),period=2))
testarma_res7 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[7,'region_txt'])

testarma=Arima(data8_count$count,order=c(5,2,3))
testarma_res8 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[8,'region_txt'])

testarma=Arima(data9_count$count,order=c(3,1,2),seasonal=list(order=c(0,0,1),period=2))
testarma_res9 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[9,'region_txt'])

testarma=Arima(data10_count$count,order=c(5,1,5),seasonal=list(order=c(3,0,1),period=4))
testarma_res10 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[10,'region_txt'])

testarma=Arima(data11_count$count,order=c(5,1,3),seasonal=list(order=c(2,0,1),period=2))
testarma_res11 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[11,'region_txt'])

testarma=Arima(data12_count$count,order=c(2,1,3))
testarma_res12 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=5)
plot.forecast(pmdarmaforecast,main=reg_uniq[12,'region_txt'])


```

\begin{center}
Yearly Forecast
\end{center}

```{r,fig.height=9,fig.width=7,echo=FALSE}
# Checking modeling residuals
par(mfrow=c(6,3), mar=c(2,4,6,2))
for (i in 1:n){
  testarma_res = get(paste0("testarma_res",i))
  plot(testarma_res,main=reg_uniq[i,'region_txt'])
  acf(testarma_res)
  pacf(testarma_res)
}
```

\begin{center}
Residuals
\end{center}






```{r,echo = F,fig.height=6.5,fig.width=6, fig.align = 'center'}
par(mfrow = c(4,3),mar=c(4,2,1.5,1))
for(i in 1:n){
  plot(get(paste0("ts",i)),  main = reg_uniq[i,'region_txt'], ylab = "count")
}



```

\begin{center}
Monthly Original Data
\end{center}

```{r, fig.height=8,fig.width=7, echo=FALSE}
# ACF and PACF for monthly data

par(mfrow = c(4,3),mar=c(1,2,3,1))

for(i in 1:n){
  var = paste0("diff",i)
  data_c = get(paste0("data",i,"_month"))
  assign(var, diff(data_c$count))
  data_diff = get(paste0("diff",i))
  plot(data_diff, type = 'l', main = reg_uniq[i,'region_txt'])

}
```
\begin{center}
Differenced Data
\end{center}

```{r, fig.height=8,fig.width=7, echo=F}
par(mfrow = c(4,3),mar=c(1,2,3,1))
for(i in 1:n){
  data_diff = get(paste0("diff",i))
  acf(data_diff,main = reg_uniq[i,'region_txt'])
}
```

\begin{center}
acf
\end{center}

```{r, fig.height=8,fig.width=7, echo=F}
par(mfrow = c(4,3),mar=c(1,2,3,1))
for(i in 1:n){
  data_diff = get(paste0("diff",i))
  pacf(data_diff,main = reg_uniq[i,'region_txt'])
}
```

\begin{center}
pacf
\end{center}

```{r, fig.height=8,fig.width=7, echo=F}
# Periodogram for monthly data
par(mfrow = c(4,3))
for(i in 1:n){
  data_diff = get(paste0("diff",i))
  var = paste0("perio",i)
  assign(var,spec.pgram(data_diff,taper=0,log="no",main=reg_uniq[i,'region_txt']))
}

```

\begin{center}
Periodogram
\end{center}

```{r, fig.height=8,fig.width=7, echo = F}
# (S)ARIMA modeling for 12 regions

par(mfrow = c(4,3))

# North America
testarma=Arima(ts1,order=c(5,1,1))
testarma_res1 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[1,'region_txt'])


testarma=Arima(ts2,order=c(5,1,5),seasonal=list(order=c(1,0,1),period=2))
testarma_res2 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[2,'region_txt'])


testarma=Arima(ts3,order=c(7,1,5),seasonal=list(order=c(2,0,1),period=4))
testarma_res3 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[3,'region_txt'])

testarma=Arima(ts4,order=c(5,1,2),seasonal=list(order=c(1,0,1),period=3))
testarma_res4 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[4,'region_txt'])

testarma=Arima(ts5,order=c(6,1,1))
testarma_res5 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[5,'region_txt'])

testarma=Arima(ts6,order=c(5,1,5),seasonal=list(order=c(2,0,1),period=2))
testarma_res6 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[6,'region_txt'])

testarma=Arima(ts7,order=c(5,1,5),seasonal=list(order=c(1,0,1),period=3))
testarma_res7 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[7,'region_txt'])

testarma=Arima(ts8,order=c(3,1,5),seasonal=list(order=c(1,0,1),period=3))
testarma_res8 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[8,'region_txt'])

testarma=Arima(ts9,order=c(2,1,5),seasonal=list(order=c(0,0,1),period=3))
testarma_res9 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[9,'region_txt'])

testarma=Arima(ts10,order=c(5,1,5),seasonal=list(order=c(1,0,1),period=2))
testarma_res10 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[10,'region_txt'])

testarma=Arima(ts11,order=c(3,1,3),seasonal=list(order=c(1,0,1),period=3))
testarma_res11 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[11,'region_txt'])

testarma=Arima(ts12,order=c(3,1,2),seasonal=list(order=c(0,0,1),period=2))
testarma_res12 = testarma$residuals
pmdarmaforecast=forecast.Arima(testarma,h=20)
plot.forecast(pmdarmaforecast,main=reg_uniq[12,'region_txt'])
```

\begin{center}
Forecast - Monthly
\end{center}

```{r, fig.height=9,fig.width=7, echo = F}
# Checking modeling residuals
par(mfrow=c(6,3), mar=c(2,4,6,2))
for (i in 1:n){
  testarma_res = get(paste0("testarma_res",i))
  plot(testarma_res,main=reg_uniq[i,'region_txt'])
  acf(testarma_res)
  pacf(testarma_res)
}
```

\begin{center}
Residuals
\end{center}
